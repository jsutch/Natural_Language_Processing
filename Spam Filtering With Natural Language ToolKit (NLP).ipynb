{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Viz imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True # in matplotlib, edge borders are turned off by default. \n",
    "sns.set_style(\"darkgrid\") # set a grey grid as a background\n",
    "\n",
    "# ML imports\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "# Linear Regression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Logistic Regression\n",
    "#\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing (NLP) Demo\n",
    "\n",
    "\n",
    "## Building a spam filter with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK's package and download manager\n",
    "# nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [line.rstrip() for line in open('/Users/person/Coding/Udemy/Python3_Data_Science_And_Machine_Learning/Refactored_Py_DS_ML_Bootcamp-master/20-Natural-Language-Processing/smsspamcollection/SMSSpamCollection')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that this is tab separated data\n",
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... \n",
      "\n",
      "1 ham\tOk lar... Joking wif u oni... \n",
      "\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's \n",
      "\n",
      "3 ham\tU dun say so early hor... U c already then say... \n",
      "\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though \n",
      "\n",
      "5 spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv \n",
      "\n",
      "6 ham\tEven my brother is not like to speak with me. They treat me like aids patent. \n",
      "\n",
      "7 ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune \n",
      "\n",
      "8 spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only. \n",
      "\n",
      "9 spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out messages\n",
    "for mess_no, message in enumerate(messages[:10]):\n",
    "    print(mess_no, message, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the list into a dataframe\n",
    "messages = pd.read_csv('/Users/person/Coding/Udemy/Python3_Data_Science_And_Machine_Learning/Refactored_Py_DS_ML_Bootcamp-master/20-Natural-Language-Processing/smsspamcollection/SMSSpamCollection',\n",
    "                       sep='\\t',names=['label','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use groupby to break down the data along ham/spam labels for better description\n",
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Natural Language Processing a big part of the work will be feature engineering. The better your domain knowledge of the data, the better you can engineer features from it. Feature engineering is a big part of spam detection in general. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['length'] = messages['message'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1246e45c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD7CAYAAACFfIhNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEwlJREFUeJzt3X+MZXV5x/H3zN3Z3dnuDKNxsNqCFH88rTHVgi2o4G4NCLix2B82xKpVao3JmkhDUlBXWSs21CCNRgwEpKut/lGXaqq4sqkVXAGlWqgS8SGgQCNpA9RhWfeHuzPTP+6935kdZ2bPzM6ZO3Pv+5Vs5pxzz7n3uU92zmfO777JyUkkSQLo73QBkqSVw1CQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqRiTacLWKiJiYnJ8fGFX4XdaPSxmOW6kb2YYi+m2IujdVs/BgYaTwCjx5pv1YXC+PgkY2P7F7zcyMiGRS3XjezFFHsxxV4crdv6MTo69EiV+dx9JEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKmo7TqFiPhPYG9r9CfA9cDHgSPA7sz8UET0A58CXgocAt6RmQ/WVZMkaX61hEJErAf6MnPztGn3An8M/Bi4JSJ+B/gNYH1mviIizgQ+BlxYR02SpGOra0vhpcCGiNjd+oztwLrMfAggIm4FzgGeA3wNIDO/HREvr6meeW0cHmRw3RoOHDrCvr0HOlGCJK0IdYXCfuBq4EbghcAuYGza608DpwLDwFPTpo9HxJrMPDLXGzcafYyMbFhwQY1G/5zLDQw0OOXyW3j4qi2sWcR7rzbz9aLX2Isp9uJovdqPukLhAeDBzJwEHoiIp4BnTnt9iGZIbGgNt/XPFwhQz72PRkebJRw8PM76gUbXbzF02z1djoe9mGIvjtZt/Wiv546lrrOPLqZ5fICIeC7Nlf/PI+L5EdEHnAfsAe4AXtea70zgBzXVU8n61hbD4LpVd59ASVoSda39Pg3siIhvAZM0Q2IC+BzQoHn20Xci4j+AcyPiTqAPeHtN9UiSKqglFDLzF8CbZnnpzBnzTQDvqqMGSdLCefGaJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNhFgcPjzM6OsTG4cFOlyJJy8pQmIUP25HUqwwFSVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkoranjcZEScC3wPOBY4AO4BJ4D5ga2ZORMQVwJbW65dk5t111SNJOrZathQiYgC4HjjQmnQNsC0zzwb6gAsj4jRgE3AGcBFwbR21SJKqq2v30dXAdcBjrfHTgdtbw7uAc4CzgN2ZOZmZjwJrImK0pnokSRUs+e6jiHgb8Hhm3hoR721N7svMydbw08AJwDDw5LRF29Mfn+/9G40+RkY2LLiuRqN/UcstZpmVbrG96Eb2Yoq9OFqv9qOOYwoXA5MRcQ7wMuCzwInTXh8CxoC9reGZ0+c1Pj7J2Nj+BRc1MrJhzuVGR4dmnQ4s6rNWuvl60WvsxRR7cbRu68d867nplnz3UWa+OjM3ZeZm4F7grcCuiNjcmuUCYA9wB3BeRPRHxMlAf2Y+sdT1SJKqq+3soxkuBW6IiLXA/cDOzByPiD3AXTTDaesy1SJJmkOtodDaWmjbNMvr24HtddYgSarOi9ckSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEwj4OHxxkdHWLj8GCnS5GkZWEozGP9QINTLr+FwXXLdYsoSeosQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMhQq8XkFSrzAUKvB6BUm9wrXcKrVxeJDBdWs4cOgI+/Ye6HQ5krqEWwqr1OC6NW69SFpyhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBWVQiEifrXuQiRJnVf1ctidEfE48Gngq5k5UWNNkqQOqbSlkJlnAe8HNgF3RsRHIuLUWiuTJC27hRxT+CnwY2A/8BLg4xFxVS1VSZI6otLuo4j4Z5pB8E/AmzPzsdb0784xfwO4AQhgEngXcBDY0Rq/D9iamRMRcQWwBTgCXJKZdx/PF5IkLV7VLYUbgN/LzL+luVJvO2uO+V8PkJmvArYBHwGuAbZl5tlAH3BhRJxGc5fUGcBFwLUL/gaSpCVTNRReBbyvNfyJiLgcIDMPzjZzZn4JeGdr9HnAGHA6cHtr2i7gHJqhsjszJzPzUWBNRIwu+FtIkpZE1bOPXp+ZpwNk5hsj4g5g3uMJmXkkIj4D/CHwJ8C5mdneyngaOAEYBp6ctlh7+uNzvW+j0cfIyIaKZU9frn9Ry820FO+x1BZa01L1ohvYiyn24mi92o+qoTAREWsz8xcRMUD1s5b+PCIuA74DTH/A8RDNrYe9reGZ0+c0Pj7J2Nj+imVPGRnZMOdyo6NDs06fzWI+uw7Ta15oTfP1otfYiyn24mjd1o+q67mqu4+uA+6LiJuBe1vjc4qIt0TEe1uj+4EJ4LsRsbk17QJgD3AHcF5E9EfEyUB/Zj5RsSZJ0hKrtKWQmZ+OiH8FTgUeqrDi/hfgHyLim8AAcAlwP3BDRKxtDe/MzPGI2APcRTOgti7ye0iSlkDVU1JfRvPA8frWOJl58VzzZ+bPgT+d5aVNs8y7HdhepQ5JUr2qHlPYAXwS+O/6SpEkdVrVUPifzLyx1kpWgYOHxxkdHeLAoSPs23ug0+VI0pKrGgoPt65NuIfWxWuZubu2qlao9QMNTrn8Fh6+agv7Ol2MJNWgaiiso3nLimiNTwI9FwqS1O2qnn309oh4EfAC4PvAY7VWJUnqiKpnH72b5pXJz6R50PmFwLvrK0uS1AlVL167CDgXGMvMj9O8gZ0kqctUDYV+mscR2vcuOlRPOZKkTqp6oPnzwDeB50XEV4Ev1VeSJKlTqh5o/mREfJ3mg3YyM79fb1mSpE6otPsoIj4IvBH4LeANrXFJUpepuvvof1s/+4DTWNiznSVJq0TV3UfXTx+PiF31lCNJ6qSq1ym8aNroc2g+YlOS1GWq7j6avqVwELi0hlokSR1WdffR79ddiCSp86ruPvovms9PPkjrQTs0DzpPZuapNdUmSVpmVc8iuhP4s8x8MXAh8C3gN2meoipJ6hJVjym8ODPvAsjMH0TEyZnprS4kqctUDYWxiPgwcDdwNvBIfSVJkjql6u6jNwF7gfOBh4C/qK0iSVLHVA2Fg8DPgCeBBEZqq0iS1DFVQ+F64GSaz1QYAj5bW0WSpI6pGgrPz8wPAgcz88vACTXWJEnqkKqhsCYingVMRsQQMFFjTZKkDql69tH7gTto3vfo28B7aqtIktQxVbcUTsrMAJ4PvCQz/63GmiRJHVJ1S+GdwOcy8/E6i5EkdVbVUFgXEffQPB11AiAz31RbVZKkjpg3FCJiW2ZeCVwG/Brw02WpSpLUEcfaUngNcGVm3h4R/56Zr1mOoiRJnXGsA819cwxLkrrQsUJhco5hSVIXOtbuo9Mj4k6aWwkvnjY8mZmvnG2BiBgAbgJOAdYBVwI/BHbQDJb7gK2ZORERVwBbgCPAJZl593F/ow7YODzI4Lo1HDh0hH17D3S6HElatGOFwm8v4j3fDDyZmW+JiGcC97b+bcvM2yLiOuDCiHgE2AScAZwE3Az87iI+r+MG163hlMtv4eGrtrCv08VI0nGYNxQyczHPTfgCsLM13EdzK+B04PbWtF3Aa2me3ro7MyeBRyNiTUSMrqZrIdpbCJLULZZ8jZaZ+wBa90jaCWwDrm6t/AGepnlDvWGat+JmxvR5Q6HR6GNkZMOC62o0+he13GwOHh5ndHQIoGwhtC3VZyzEQj9zKXux2tmLKfbiaL3aj1r+zI2Ik4AvAp/KzM9HxEenvTwEjNF8aM/QLNPnNT4+ydjY/gXXNDKyYc7l2iv4qtYPNH4pDNoWU9tiTK95oZ85Xy96jb2YYi+O1m39qLqeq3rvo8oi4tnAbuCyzLypNfmeiNjcGr4A2EPzBnvnRUR/RJwM9GfmE0tdT7fZODy44BCTpKqWPBSA9wHPAD4QEbdFxG00dyF9KCLuAtYCOzPzezTD4S6aB5m31lBL12kf1JakOtRxTOE9zH5r7U2zzLsd2L7UNUiSFqeOLQVJ0iplKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVPiEmBr4eE5Jq5VbCjVo38nUp7JJWm1ca60SPvpT0nJwS2EJTX9M51LzOQqSloOhsITaj+mUpNXKUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhkKN2re92Dg82OlSJKkSQ6FG7dteHM+N7DYOD9Z2PyVJmslQWKHaYeCN8CQtJ0NhhTIMJHWCobDKedxC0lIyFFa5pThuIUlthoIkqTAUJElFbfscIuIM4O8yc3NEvADYAUwC9wFbM3MiIq4AtgBHgEsy8+666lmp2s9ePnh4nPUDDQ4cOsK+vQc6XZakHlXLlkJE/DVwI7C+NekaYFtmng30ARdGxGnAJuAM4CLg2jpqWenaZxl5bEDSSlDX7qOHgD+aNn46cHtreBdwDnAWsDszJzPzUWBNRIzWVI8kqYJaQiEzbwYOT5vUl5mTreGngROAYeCpafO0p3ed9mmjnjoqaaVbrn0VE9OGh4AxYG9reOb0eTUafYyMbFhwAY1G/6KWWwrtXUMAP/rw+YyODpVjCDO1A2Qxqn6/TvZipbEXU+zF0Xq1H8sVCvdExObMvA24APgG8CDw0Yi4Gvh1oD8znzjWG42PTzI2tn/BBYyMbJhzueW8t1A7IB6+akv5OdfrC1W1L/P1otfYiyn24mjd1o+q67nlCoVLgRsiYi1wP7AzM8cjYg9wF83dWFuXqRZJ0hxqC4XMfBg4szX8AM0zjWbOsx3YXlcNkqSF8eI1SVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSUVP35KzfdtqSVJTT28ptG9bLUlq6ulQkCQdzVCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVPTU5bztK5gPHDrCvr0HOl2OJK04PbWl0L6Cua+/r/JDrCWpl/RUKLStH2h4ewtJmkVPhoIkaXaGgiSpMBQkSYWhIEkqDIUucfDwOKOjQ2wcHux0KZJWMUOhS7TPqPJJcpKOh6EgSSoMBUlS4b6GLuUtPSQthlsKXaZ9wLl9Sw+PMUhaCEOhy3gLD0nHw1CQJBWGgiSpcIdzj5h+4HnmuAeiJbV1PBQioh/4FPBS4BDwjsx8sLNVdY/2gWeAUy6/hR99+HwGBhoMtMYfvmoL+6bN3w6Lg4fHWT/QKD8ND6k3rITdR28A1mfmK4DLgY91uJ6uMvPA88zxmbfHaJ+11J6v/bP9YKKhkQ2VbqexcXjwqPln/qxyO46Z77HSbuHRrm+l1SUdj5UQCmcBXwPIzG8DL+9sOb1l5kr/WPPNFRIzf84VLnMtX+U92su0V8IzV8rHCqJjhctcITTXyn/mab/HComVFCKLrXUlfYeltlK/23LX1Tc5ObksHzSXiLgRuDkzd7XGHwVOzcwjcyzyOPDIctUnSV3iecDosWbq+DEFYC8w/U/U/nkCASp8KUnS4qyE3Ud3AK8DiIgzgR90thxJ6l0rYUvhi8C5EXEn0Ae8vcP1SFLP6vgxBUnSyrESdh9JklYIQ0GSVKyEYwq16sUrpiNiALgJOAVYB1wJ/BDYAUwC9wFbM3MiIq4AtgBHgEsy8+5O1Fy3iDgR+B5wLs3vuoPe7cV7gT8A1tL83bidHuxH6/fkMzR/T8aBv6TH/29Ab2wp9OIV028GnszMs4HzgU8C1wDbWtP6gAsj4jRgE3AGcBFwbYfqrVXrl/96oH2fjl7uxWbglcCraH7fk+jdfrwOWJOZrwT+BvgIvduLohdCoRevmP4C8IHWcB/Nv25Op/kXIcAu4ByavdmdmZOZ+SiwJiK68TqQq4HrgMda473ci/Nonvb9ReDLwFfo3X48QPN79QPDwGF6txdFL4TCMPDUtPHxiOjq3WaZuS8zn46IIWAnsA3oy8z2qWZPAyfwy71pT+8aEfE24PHMvHXa5J7sRcuzaP5h9EbgXcDnaF4w2ov92Edz19GPgBuAT9Db/zeA3giFhV4x3RUi4iTgG8A/ZubngYlpLw8BY/xyb9rTu8nFNK+DuQ14GfBZ4MRpr/dSLwCeBG7NzF9kZgIHOXoF10v9+CuavXgRzWOOn6F5nKWtl3pR9EIo9NwV0xHxbGA3cFlm3tSafE9rfzLABcAemr05LyL6I+JkmoH5xLIXXKPMfHVmbsrMzcC9wFuBXb3Yi5ZvAedHRF9EPBf4FeDrPdqPnzG1BfB/wAA9+nsyXVfvRmnpxSum3wc8A/hARLSPLbwH+ERErAXuB3Zm5nhE7AHuovkHwtaOVLv8LgVu6MVeZOZXIuLVwN1Mfc+f0Jv9+Hvgptb3XEvz9+a79GYvCq9oliQVvbD7SJJUkaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqfh/gMbGOzUYw/MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See the distribution of message length\n",
    "# \"Text Length\" may be a good feature to think about\n",
    "messages['length'].plot.hist(bins=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max message length is 910, mean 80.5\n",
    "messages['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>ham</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "1085   ham  For me the love should start with attraction.i...     910"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's find the largest message using pandas masking\n",
    "messages[messages['length']> 900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To read the message\n",
    "messages[messages['length']> 900]['message'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we notice that spam messages tend to be shorter than ham messages - there's a drop off around 150. This looks like a good data feature for evaluating spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x12d4a1518>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x12d3e80f0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Break out histograms of length by label\n",
    "# sort of Pandas built-in viz version of 'FacetGrid'\n",
    "messages.hist(column='length',by='label', bins=60, figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of how this will work\n",
    "mess = 'sample message! Notice: it has punctuation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The string punctuation list \n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension to extract punctuation from our message\n",
    "nopunc = [c for c  in mess if c not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', 'a', 'm', 'p', 'l', 'e', ' ', 'm', 'e', 's', 's', 'a', 'g', 'e', ' ', 'N', 'o', 't', 'i', 'c', 'e', ' ', 'i', 't', ' ', 'h', 'a', 's', ' ', 'p', 'u', 'n', 'c', 't', 'u', 'a', 't', 'i', 'o', 'n']\n"
     ]
    }
   ],
   "source": [
    "# Notice that it's remove and left a blank for every instance of punctuation.\n",
    "print(nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the stopwords\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The english stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the words back together from the letters\n",
    "nopunc = ''.join(nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample message Notice it has punctuation'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example\n",
    "x = ['a','b','c','d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+++b+++c+++d'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding elements into the '' will sandwich it in the output\n",
    "'+++'.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytest='bob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abobbbobcbobd'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Works with fstrings!!!\n",
    "f'{mytest}'.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'message', 'Notice', 'it', 'has', 'punctuation']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make nopunc a list so we can use list comprehension to remove stopwords\n",
    "nopunc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "clean_mess = [word for word in nopunc.split()  if word.lower() not in stopwords.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'message', 'Notice', 'punctuation']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting this all into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    1. remove punc\n",
    "    2. remove stopwords\n",
    "    3. return list of clean text words\n",
    "    \"\"\"\n",
    "    nopunc = [char for char in mess if char not in string.punctuation ]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split()  if word.lower() not in stopwords.words('english')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    U dun say so early hor... U c already then say...\n",
       "4    Nah I don't think he goes to usf, he lives aro...\n",
       "5    FreeMsg Hey there darling it's been 3 week's n...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['message'][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "5    [FreeMsg, Hey, darling, 3, weeks, word, back, ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now tokenize these messages\n",
    "\n",
    "messages['message'][:6].apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using stemming and vectorization to process text data\n",
    "\n",
    "**Stemming** is another way to process text data. Stemming is a way to take words that mean the same thing or have a common stem (Go, going, gone, leave) and view them as one word. (run running ran).\n",
    "\n",
    "\n",
    "The problem is that you need a reference dictionary to make that work. Luckily NLTK has a lot of these built in datasets, corpii and references.\n",
    "\n",
    "Focusing back to **Vectorization**\n",
    "\n",
    "Now to convert each message into a vector that scikit-learn's algorithm model can work with.\n",
    "\n",
    "*Convert each message as a list of tokens into a Vector*:\n",
    "\n",
    "1. Count how many times does a word occur in each message? -  **Term Frequency**\n",
    "2. Weigh the counts so that frequent tokens get lower weight. - **Inverse Document Frequency**\n",
    "3. Normalize the vectors to unit length, to abstract from the original text length - **L2 norm**\n",
    "\n",
    "\n",
    "We will use scikit-learn's **CountVectorizer** model.\n",
    "\n",
    "We can think of this as a two dimensional matrix. \n",
    "   - One dimension is the entire vocabulary - one row per word\n",
    "   - the other dimension are the actual documents - one column per text message\n",
    "   \n",
    "It will create a matrix something like this:\n",
    "\n",
    "\n",
    "\n",
    "| wordcount   | Message 1   | Message 2     | ...| Message N|\n",
    "| :---        | :----       | :---          |:---| :---     |\n",
    "| Word 1 Count| 0           |  1            | ...| 0        |\n",
    "| Word 2 Count| 1           |  1            | ...| 0        |\n",
    "| Word 3 Count| 1           |  0            | ...| 1        |\n",
    "\n",
    "\n",
    "Because many words won't have entries, scikit-learn will output a *Sparse Matrix* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n"
     ]
    }
   ],
   "source": [
    "# may take some time to run.\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(messages['message'])\n",
    "\n",
    "# Print total number of vocabulary words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "# the 4th message\n",
    "message4 = messages['message'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4068)\t2\n",
      "  (0, 4629)\t1\n",
      "  (0, 5261)\t1\n",
      "  (0, 6204)\t1\n",
      "  (0, 6222)\t1\n",
      "  (0, 7186)\t1\n",
      "  (0, 9554)\t2\n",
      "Bow4 Shape (1, 11425)\n"
     ]
    }
   ],
   "source": [
    "# The Vector Representation\n",
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "# Note that there are only 7 unique words in message 4 after removing all the stopwords\n",
    "# Two of them appear twice \n",
    "print('Bow4 Shape', bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Check to see which ones appear twice using the bow_transformer and the word number (4068 and 9554 here)\n",
    "bow_transformer.get_feature_names()[4068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.get_feature_names()[9554]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**the Bag Of Words corpus is a large sparse matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could take some time.\n",
    "messages_bow = bow_transformer.transform(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the sparse matrix:  (5572, 11425)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the sparse matrix: ', messages_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50548"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the amount of non-zero occurrences\n",
    "messages_bow.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Sparsity\n",
    "sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))\n",
    "# using round() will drop the sparsity to 0\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.07940295412668218\n"
     ]
    }
   ],
   "source": [
    "# Here's the real sparsity\n",
    "# A comparison of the non-zero messages to the total number of messages\n",
    "print('sparsity: {}'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the counting, the term weighting and normalization can be done with TF-IDF, using scikit-learn's TfidfTransformer.\n",
    "\n",
    "\n",
    "### Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF stands for *term frequency-inverse document frequency*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model object and fit it to the BOW\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the 4th message we did earlier\n",
    "tfidf4 = tfidf_transformer.transform(bow4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11425)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we've transformed a word count into a TFIDF**\n",
    "\n",
    "You can interpret the numbers as a *Weight Value* for each of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9554)\t0.5385626262927564\n",
      "  (0, 7186)\t0.4389365653379857\n",
      "  (0, 6222)\t0.3187216892949149\n",
      "  (0, 6204)\t0.29953799723697416\n",
      "  (0, 5261)\t0.29729957405868723\n",
      "  (0, 4629)\t0.26619801906087187\n",
      "  (0, 4068)\t0.40832589933384067\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the *Inverse Document Frequency* for a particular word.\n",
    "\n",
    "\n",
    "Check the document frequency for the word 'University'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.23939443, 8.5270765 , 8.93254161, ..., 8.93254161, 6.98663146,\n",
       "       8.93254161])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tfidf_transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.93254160700959"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a little hairy, but this is the Inverse Document Frequency for University\n",
    "tfidf_transformer.idf_[bow_transformer.vocabulary_['University']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's convert the entire Bag Of Words corpus into a TF-IDF corpus at once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an object, and pass in the entire corpus of messages_bow rather than a single entry\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 11425)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11163)\t0.23026685592418913\n",
      "  (0, 10965)\t0.19073428545061483\n",
      "  (0, 8917)\t0.24704652376837993\n",
      "  (0, 8336)\t0.17046869292195632\n",
      "  (0, 7668)\t0.26403384065473806\n",
      "  (0, 7555)\t0.31253856260694546\n",
      "  (0, 6937)\t0.1834692413608692\n",
      "  (0, 6906)\t0.15158474664662352\n",
      "  (0, 6217)\t0.18915557732842803\n",
      "  (0, 5769)\t0.24984711892976424\n",
      "  (0, 5218)\t0.26870593862526665\n",
      "  (0, 5217)\t0.29835184088197164\n",
      "  (0, 4653)\t0.31253856260694546\n",
      "  (0, 2060)\t0.24203960256420656\n",
      "  (0, 1483)\t0.31253856260694546\n",
      "  (0, 1110)\t0.2882862016308418\n",
      "  (1, 11072)\t0.40061560982443056\n",
      "  (1, 10698)\t0.2063637481323008\n",
      "  (1, 8590)\t0.5043405901305854\n",
      "  (1, 7701)\t0.3767401070812794\n",
      "  (1, 3064)\t0.2911995411244838\n",
      "  (1, 2451)\t0.561988811929381\n",
      "  (2, 11123)\t0.19104387220509106\n",
      "  (2, 11084)\t0.15898145347176754\n",
      "  (2, 10686)\t0.13995540820792943\n",
      "  :\t:\n",
      "  (5568, 6882)\t0.31367469776242124\n",
      "  (5568, 6691)\t0.47781076401785183\n",
      "  (5568, 6354)\t0.5575721048646767\n",
      "  (5568, 4880)\t0.3853122086093004\n",
      "  (5569, 10199)\t0.520467167163554\n",
      "  (5569, 8252)\t0.4328299709057074\n",
      "  (5569, 3721)\t0.520467167163554\n",
      "  (5569, 3228)\t0.520467167163554\n",
      "  (5570, 11006)\t0.20434525994453323\n",
      "  (5570, 10787)\t0.22867843486502568\n",
      "  (5570, 9915)\t0.22380228376189748\n",
      "  (5570, 8420)\t0.22651675757217207\n",
      "  (5570, 7800)\t0.17243888184764117\n",
      "  (5570, 7394)\t0.3071475234812021\n",
      "  (5570, 7287)\t0.26786677935500575\n",
      "  (5570, 6984)\t0.2641640440122445\n",
      "  (5570, 6799)\t0.294185812624235\n",
      "  (5570, 6699)\t0.2008376534326777\n",
      "  (5570, 6282)\t0.2607702439080329\n",
      "  (5570, 5251)\t0.302353515740512\n",
      "  (5570, 5055)\t0.36357250744470165\n",
      "  (5570, 4508)\t0.3470692575834817\n",
      "  (5571, 10648)\t0.539218119882165\n",
      "  (5571, 8348)\t0.48542915408134024\n",
      "  (5571, 3431)\t0.6881877327870772\n"
     ]
    }
   ],
   "source": [
    "print(messages_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Fit Syntax*   \n",
    "MultinomialNB.fit(self, X, y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and fit it to the TFIDF of the messages with \n",
    "spam_detect_model = MultinomialNB().fit(messages_tfidf,messages['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now try to classify a single random message and see how we do**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for the prediction. Remember that the [0] means the message element of the matrix\n",
    "spam_detect_model.predict(tfidf4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check the 4th message for its label\n",
    "messages['label'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To run this on all the messages:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = spam_detect_model.predict(messages_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this case the Testing set is the same as the Training Set, so we can't estimate the predictive power of the model**\n",
    "\n",
    "Now to use the model with Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Train/Test Split\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(messages['message'],messages['label'], test_size=0.3, random_state=101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4028        Yes, princess. Are you going to make me moan?\n",
       "1310              Ok, be careful ! Don't text and drive !\n",
       "5469                                              Ok lor.\n",
       "5375    I cant pick the phone right now. Pls send a me...\n",
       "3814                Pls i wont belive god.not only jesus.\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pipelines\n",
    "What we haven't done is all the steps we did before to vectorize, make the Bag Of Words, etc. But this is such a common process that SciKit-Learn already has a Data Pipeline feature to summarize the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an instance of the pipeline model\n",
    "# pipline only takes a 'steps' argument, so tell it what you want it to do\n",
    "# the first argument is a tuple\n",
    "# 1. Strings To Token Integer Step with CountVectorizer\n",
    "# 2. TFIDF transform with TfidfTransformer\n",
    "# 3. Train this on the model with MultinomialNB (or another Classifier)\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',MultinomialNB())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mae a fitted pipeline object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x12ce33400>, binary=False,\n",
       "        decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treat the pipeline model as a normal Estimator\n",
    "# This will perform those three steps in the pipeline\n",
    "# Will take some time - it's fitting and training all the data\n",
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making predictions**\n",
    "\n",
    "96% - pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1475\n",
      "        spam       1.00      0.65      0.79       197\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1672\n",
      "   macro avg       0.98      0.83      0.88      1672\n",
      "weighted avg       0.96      0.96      0.96      1672\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[1475    0]\n",
      " [  68  129]]\n"
     ]
    }
   ],
   "source": [
    "# Printing results\n",
    "print('Classification Report')\n",
    "print(classification_report(label_test,predictions))\n",
    "print('\\n')\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(label_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test with a different Classifier\n",
    "\n",
    "Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an instance of the pipeline model\n",
    "# pipline only takes a 'steps' argument, so tell it what you want it to do\n",
    "# the first argument is a tuple\n",
    "# 1. Strings To Token Integer Step with CountVectorizer\n",
    "# 2. TFIDF transform with TfidfTransformer\n",
    "# 3. Train this on the model with MultinomialNB (or another Classifier)\n",
    "pipeline1 = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x12ce33400>, binary=False,\n",
       "        decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = pipeline1.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1475\n",
      "        spam       0.98      0.73      0.83       197\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1672\n",
      "   macro avg       0.97      0.86      0.91      1672\n",
      "weighted avg       0.97      0.97      0.96      1672\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[1472    3]\n",
      " [  54  143]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(label_test,predictions1))\n",
    "print('\\n')\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(label_test,predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
